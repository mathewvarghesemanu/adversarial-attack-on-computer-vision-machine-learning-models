{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: six in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from adversarial-robustness-toolbox) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from adversarial-robustness-toolbox) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from adversarial-robustness-toolbox) (1.24.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from adversarial-robustness-toolbox) (4.64.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from adversarial-robustness-toolbox) (65.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages (from tqdm->adversarial-robustness-toolbox) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 22s 364us/sample - loss: 0.2553 - acc: 0.9221\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 22s 364us/sample - loss: 0.0855 - acc: 0.9744\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 22s 366us/sample - loss: 0.0655 - acc: 0.9808\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.0514 - acc: 0.9838\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.0447 - acc: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 99.09%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Trains a convolutional neural network on the MNIST dataset, then attacks it with the FGSM attack.\"\"\"\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.utils import load_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Read MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"mnist\"))\n",
    "\n",
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "preds = np.argmax(classifier.predict(x_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc * 100))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing FGSM on Adversarial samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy on adversarial sample: 88.77%\n"
     ]
    }
   ],
   "source": [
    "# Craft adversarial samples with FGSM\n",
    "epsilon = 0.1  # Maximum perturbation\n",
    "adv_crafter_fgsm = FastGradientMethod(classifier, eps=epsilon)\n",
    "x_test_adv_fgsm = adv_crafter_fgsm.generate(x=x_test)\n",
    "\n",
    "# Evaluate the classifier on the adversarial examples\n",
    "preds = np.argmax(classifier.predict(x_test_adv_fgsm), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy on adversarial sample: %.2f%%\" % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training - Training FGSM on combined samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating adversarial train examples\n",
    "x_train_adv_fgsm = adv_crafter_fgsm.generate(x=x_train)\n",
    "\n",
    "#combining adv train and test data\n",
    "x_combined_train_fgsm = np.concatenate([x_train, x_train_adv_fgsm])\n",
    "x_combined_test_fgsm = np.concatenate([x_test, x_test_adv_fgsm])\n",
    "y_combined_train_fgsm = np.concatenate([y_train,y_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples\n",
      "Epoch 1/5\n",
      "120000/120000 [==============================] - 44s 369us/sample - loss: 0.0166 - acc: 0.9947\n",
      "Epoch 2/5\n",
      "120000/120000 [==============================] - 43s 362us/sample - loss: 0.0142 - acc: 0.9956\n",
      "Epoch 3/5\n",
      "120000/120000 [==============================] - 45s 373us/sample - loss: 0.0134 - acc: 0.9955\n",
      "Epoch 4/5\n",
      "120000/120000 [==============================] - 45s 371us/sample - loss: 0.0117 - acc: 0.9959\n",
      "Epoch 5/5\n",
      "120000/120000 [==============================] - 45s 373us/sample - loss: 0.0111 - acc: 0.9963\n",
      "\n",
      "Test accuracy: 99.14%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "classifier_adv_fgsm = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier_adv_fgsm.fit(x_combined_train_fgsm, y_combined_train_fgsm, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "preds_adv_fgsm = np.argmax(classifier_adv_fgsm.predict(x_test_adv_fgsm), axis=1)\n",
    "acc_fgsm = np.sum(preds_adv_fgsm == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc_fgsm * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGD "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD Vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 22s 370us/sample - loss: 0.2382 - acc: 0.9271\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 22s 364us/sample - loss: 0.0840 - acc: 0.9751\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 22s 368us/sample - loss: 0.0641 - acc: 0.9810\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 22s 369us/sample - loss: 0.0505 - acc: 0.9846\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 22s 372us/sample - loss: 0.0433 - acc: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 99.14%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Trains a convolutional neural network on the MNIST dataset, then attacks it with the FGSM attack.\"\"\"\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion.projected_gradient_descent.projected_gradient_descent import ProjectedGradientDescent\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.utils import load_dataset\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# Read MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"mnist\"))\n",
    "\n",
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "preds = np.argmax(classifier.predict(x_test), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc * 100))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing PGD on Adversarial samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy on adversarial sample: 0.63%\n"
     ]
    }
   ],
   "source": [
    "# Craft adversarial samples with PGD\n",
    "epsilon = 0.1  # Maximum perturbation\n",
    "adv_crafter = ProjectedGradientDescent(classifier, norm=np.inf, eps=0.2, eps_step=0.05, verbose=False)\n",
    "x_test_adv = adv_crafter.generate(x=x_test)\n",
    "\n",
    "# Evaluate the classifier on the adversarial examples\n",
    "preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy on adversarial sample: %.2f%%\" % (acc * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training - Training PGD on combined samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples\n",
      "Epoch 1/5\n",
      "120000/120000 [==============================] - 44s 363us/sample - loss: 0.1496 - acc: 0.9577\n",
      "Epoch 2/5\n",
      "120000/120000 [==============================] - 44s 364us/sample - loss: 0.0369 - acc: 0.9893\n",
      "Epoch 3/5\n",
      "120000/120000 [==============================] - 44s 363us/sample - loss: 0.0288 - acc: 0.9916\n",
      "Epoch 4/5\n",
      "120000/120000 [==============================] - 44s 366us/sample - loss: 0.0249 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "120000/120000 [==============================] - 44s 363us/sample - loss: 0.0194 - acc: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 99.02%\n"
     ]
    }
   ],
   "source": [
    "# generating adversarial train examples\n",
    "x_train_adv = adv_crafter.generate(x=x_train)\n",
    "\n",
    "#combining adv train and test data\n",
    "x_combined_train = np.concatenate([x_train, x_train_adv])\n",
    "x_combined_test = np.concatenate([x_test, x_test_adv])\n",
    "y_combined_train = np.concatenate([y_train,y_train])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "classifier_adv = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier_adv.fit(x_combined_train, y_combined_train, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "preds_adv = np.argmax(classifier_adv.predict(x_test_adv), axis=1)\n",
    "acc = np.sum(preds_adv == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfool - Training on Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2064 - acc: 0.9408\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0984 - acc: 0.9706\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0745 - acc: 0.9775\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0645 - acc: 0.9805\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0588 - acc: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepFool: 100%|██████████| 60000/60000 [04:54<00:00, 203.91it/s]\n",
      "DeepFool: 100%|██████████| 10000/10000 [00:46<00:00, 216.33it/s]\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:32: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv = tf.layers.conv2d(inputs_tf, 4, 5, activation=tf.nn.relu)\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:33: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  conv = tf.layers.max_pooling2d(conv, 2, 2)\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:34: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  fc = tf.layers.flatten(conv)\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:37: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.layers.dense(fc, 10)\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m# Evaluate the CNN on the adversarial samples\u001b[39;00m\n\u001b[0;32m     90\u001b[0m preds_df \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mpredict(x_test_adv_df)\n\u001b[1;32m---> 91\u001b[0m acc_df \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mequal(np\u001b[39m.\u001b[39;49margmax(preds, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), np\u001b[39m.\u001b[39margmax(y_test_df, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))) \u001b[39m/\u001b[39m y_test_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     92\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAccuracy on adversarial samples: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (acc_df \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1242\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Trains a CNN on the MNIST dataset using the Keras backend, then generates adversarial images using DeepFool\n",
    "and uses them to attack a CNN trained on MNIST using TensorFlow. This is to show how to perform a\n",
    "black-box attack: the attack never has access to the parameters of the TensorFlow model.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import keras\n",
    "import keras.backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from art.attacks.evasion import DeepFool\n",
    "from art.estimators.classification import KerasClassifier, TensorFlowClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cnn_mnist_tf(input_shape):\n",
    "    labels_tf = tf.placeholder(tf.float32, [None, 10])\n",
    "    inputs_tf = tf.placeholder(tf.float32, [None] + list(input_shape))\n",
    "\n",
    "    # Define the TensorFlow graph\n",
    "    conv = tf.layers.conv2d(inputs_tf, 4, 5, activation=tf.nn.relu)\n",
    "    conv = tf.layers.max_pooling2d(conv, 2, 2)\n",
    "    fc = tf.layers.flatten(conv)\n",
    "\n",
    "    # Logits layer\n",
    "    logits = tf.layers.dense(fc, 10)\n",
    "\n",
    "    # Train operator\n",
    "    loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=labels_tf))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_tf = optimizer.minimize(loss)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    classifier = TensorFlowClassifier(\n",
    "        clip_values=(0, 1), input_ph=inputs_tf, output=logits, loss=loss, train=train_tf, labels_ph=labels_tf, sess=sess\n",
    "    )\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def cnn_mnist_k(input_shape):\n",
    "    # Create simple CNN\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(4, kernel_size=(5, 5), activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.01), metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    classifier = KerasClassifier(model=model, clip_values=(0, 1))\n",
    "    return classifier\n",
    "\n",
    "\n",
    "# Get session\n",
    "session = tf.Session()\n",
    "k.set_session(session)\n",
    "\n",
    "# Read MNIST dataset\n",
    "(x_train_df, y_train_df), (x_test_df, y_test_df), min_, max_ = load_mnist()\n",
    "\n",
    "# Construct and train a convolutional neural network on MNIST using Keras\n",
    "source = cnn_mnist_k(x_train_df.shape[1:])\n",
    "source.fit(x_train_df, y_train_df, nb_epochs=5, batch_size=128)\n",
    "\n",
    "# Craft adversarial samples with DeepFool\n",
    "adv_crafter_df = DeepFool(source)\n",
    "x_train_adv_df = adv_crafter_df.generate(x_train_df)\n",
    "x_test_adv_df = adv_crafter_df.generate(x_test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training - Training Deepfool on combined samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on adversarial samples: 18.26%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the adversarial samples\n",
    "preds_df = target.predict(x_test_adv_df)\n",
    "acc_df = np.sum(np.equal(np.argmax(preds_df, axis=1), np.argmax(y_test_df, axis=1))) / y_test_df.shape[0]\n",
    "print(\"\\nAccuracy on adversarial samples: %.2f%%\" % (acc_df * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:32: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv = tf.layers.conv2d(inputs_tf, 4, 5, activation=tf.nn.relu)\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:33: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  conv = tf.layers.max_pooling2d(conv, 2, 2)\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:34: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  fc = tf.layers.flatten(conv)\n",
      "C:\\Users\\mvarghese\\AppData\\Local\\Temp\\ipykernel_26108\\3756833810.py:37: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.layers.dense(fc, 10)\n"
     ]
    }
   ],
   "source": [
    "#combining adv train and test data\n",
    "x_combined_train_df = np.concatenate([x_train_df, x_train_adv_df])\n",
    "x_combined_test_df = np.concatenate([x_test_df, x_test_adv_df])\n",
    "y_combined_train_df = np.concatenate([y_train_df,y_train_df])\n",
    "\n",
    "# Construct and train a convolutional neural network\n",
    "target = cnn_mnist_tf(x_combined_train_df.shape[1:])\n",
    "target.fit(x_combined_train_df, y_combined_train_df, nb_epochs=5, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 97.55%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier on the test set\n",
    "preds_adv_df = np.argmax(target.predict(x_test_adv_df), axis=1)\n",
    "acc_adv_df = np.sum(preds_adv_df == np.argmax(y_test_df, axis=1)) / y_test_df.shape[0]\n",
    "print(\"\\nTest accuracy: %.2f%%\" % (acc_adv_df * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave this, just plain trials for using the ART library to find more evaluation metrics, this will only work with FGSM as other attacks are not supported, we need to find other ways of calculating the robustness understanding the code they use \n",
    "\n",
    "reference : https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/art/metrics/metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "[[[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[1.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [1.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [1.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.01667255]\n   [0.45018354]\n   [0.12508452]\n   ...\n   [0.20973589]\n   [0.6356886 ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.6027053 ]\n   [0.25512254]\n   ...\n   [0.36489058]\n   [0.25411642]\n   [0.        ]]\n\n  [[0.        ]\n   [0.66581476]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.18287487]\n   [0.        ]]\n\n  ...\n\n  [[0.00566642]\n   [0.00894436]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.00486345]\n   [0.        ]\n   ...\n   [0.08693738]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.13622476]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.42691484]\n   [0.        ]\n   [0.33015522]\n   ...\n   [0.07108697]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[0.24962477]\n   [0.39402926]\n   [0.27950668]\n   ...\n   [0.6401726 ]\n   [0.14626977]\n   [0.        ]]\n\n  [[0.        ]\n   [0.21425162]\n   [0.15295058]\n   ...\n   [0.        ]\n   [0.07496338]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n ...\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.3784995 ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [0.7985576 ]\n   ...\n   [0.37855047]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.58091474]\n   [1.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [0.5503121 ]\n   ...\n   [1.        ]\n   [0.70383745]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.43769273]\n   [0.        ]]\n\n  ...\n\n  [[1.        ]\n   [1.        ]\n   [0.        ]\n   ...\n   [1.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.41746432]\n   [1.        ]\n   [0.        ]]\n\n  [[0.4744493 ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.72628874]\n   [0.50580066]\n   [0.        ]]\n\n  [[1.        ]\n   [0.41959238]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[1.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [1.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]] crafting method not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mException\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mart\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m empirical_robustness\n\u001b[0;32m      5\u001b[0m \u001b[39m# Evaluate the neural network\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#loss, acc = model.evaluate(x_test_adv, y_test)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[39m# Compute robustness and average Lp distance\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m robustness \u001b[39m=\u001b[39m empirical_robustness(target, x_test, x_test_adv_df)\n\u001b[0;32m     10\u001b[0m \u001b[39m#robustness = rv.robustness()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m avg_lp_distance \u001b[39m=\u001b[39m robustness\u001b[39m.\u001b[39mavg_lp_distance(p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\art\\metrics\\metrics.py:167\u001b[0m, in \u001b[0;36mempirical_robustness\u001b[1;34m(classifier, x, attack_name, attack_params)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mempirical_robustness\u001b[39m(\n\u001b[0;32m    147\u001b[0m     classifier: \u001b[39m\"\u001b[39m\u001b[39mCLASSIFIER_TYPE\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    148\u001b[0m     x: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m    149\u001b[0m     attack_name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    150\u001b[0m     attack_params: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mfloat\u001b[39m, np\u001b[39m.\u001b[39mndarray]:\n\u001b[0;32m    152\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m    Compute the Empirical Robustness of a classifier object over the sample `x` for a given adversarial crafting\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m    method `attack`. This is equivalent to computing the minimal perturbation that the attacker must introduce for a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39m    :return: The average empirical robustness computed on `x`.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     crafter \u001b[39m=\u001b[39m get_crafter(classifier, attack_name, attack_params)\n\u001b[0;32m    168\u001b[0m     crafter\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mminimal\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[0;32m    169\u001b[0m     adv_x \u001b[39m=\u001b[39m crafter\u001b[39m.\u001b[39mgenerate(x)\n",
      "File \u001b[1;32mc:\\Users\\mvarghese\\.conda\\envs\\pytorch\\lib\\site-packages\\art\\metrics\\metrics.py:80\u001b[0m, in \u001b[0;36mget_crafter\u001b[1;34m(classifier, attack, params)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mAvailable attacks include \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(SUPPORTED_METHODS\u001b[39m.\u001b[39mkeys()))\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mattack\u001b[39m}\u001b[39;00m\u001b[39m crafting method not supported.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mException\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m SUPPORTED_METHODS[attack]:\n\u001b[0;32m     83\u001b[0m     crafter\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mSUPPORTED_METHODS[attack][\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: [[[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[1.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [1.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [1.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.01667255]\n   [0.45018354]\n   [0.12508452]\n   ...\n   [0.20973589]\n   [0.6356886 ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.6027053 ]\n   [0.25512254]\n   ...\n   [0.36489058]\n   [0.25411642]\n   [0.        ]]\n\n  [[0.        ]\n   [0.66581476]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.18287487]\n   [0.        ]]\n\n  ...\n\n  [[0.00566642]\n   [0.00894436]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.00486345]\n   [0.        ]\n   ...\n   [0.08693738]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.13622476]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.42691484]\n   [0.        ]\n   [0.33015522]\n   ...\n   [0.07108697]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[0.24962477]\n   [0.39402926]\n   [0.27950668]\n   ...\n   [0.6401726 ]\n   [0.14626977]\n   [0.        ]]\n\n  [[0.        ]\n   [0.21425162]\n   [0.15295058]\n   ...\n   [0.        ]\n   [0.07496338]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n ...\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.3784995 ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [0.7985576 ]\n   ...\n   [0.37855047]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.58091474]\n   [1.        ]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [0.5503121 ]\n   ...\n   [1.        ]\n   [0.70383745]\n   [0.        ]]\n\n  [[1.        ]\n   [0.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.43769273]\n   [0.        ]]\n\n  ...\n\n  [[1.        ]\n   [1.        ]\n   [0.        ]\n   ...\n   [1.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [1.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]\n\n\n [[[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.41746432]\n   [1.        ]\n   [0.        ]]\n\n  [[0.4744493 ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.72628874]\n   [0.50580066]\n   [0.        ]]\n\n  [[1.        ]\n   [0.41959238]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  ...\n\n  [[1.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [1.        ]\n   [1.        ]\n   ...\n   [1.        ]\n   [0.        ]\n   [0.        ]]\n\n  [[0.        ]\n   [0.        ]\n   [0.        ]\n   ...\n   [0.        ]\n   [0.        ]\n   [0.        ]]]] crafting method not supported."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from art.metrics.metrics import empirical_robustness\n",
    "\n",
    "# Evaluate the neural network\n",
    "#loss, acc = model.evaluate(x_test_adv, y_test)\n",
    "\n",
    "# Compute robustness and average Lp distance\n",
    "robustness = empirical_robustness(target, x_test, x_test_adv_df)\n",
    "#robustness = rv.robustness()\n",
    "avg_lp_distance = robustness.avg_lp_distance(p=2)\n",
    "\n",
    "# Visualize results\n",
    "plt.bar(['Accuracy', 'Robustness', 'Avg L2 Distance'], [acc_adv_df, robustness, avg_lp_distance])\n",
    "plt.title('Neural Network Evaluation Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps :\n",
    "\n",
    "1. Consult the earlier notebook to plot visualizations for the corrupted inputs after perturbations, alternate way is to use the visualizations from the ART library used above, but it will take some time to figure out their method.\n",
    "\n",
    "2. Plot graph for the loss and accuracy for only adversarial vs adversarial training \n",
    "\n",
    "3. Include more metrics of evaluation like F1 score, AUC etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
